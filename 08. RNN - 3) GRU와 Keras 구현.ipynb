{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a21f85",
   "metadata": {},
   "source": [
    "* GRU는 LSTM의 장기 의존성 문제를 해결하면서, 은닉상태를 업데이트하는 계산을 줄일 수 있음\n",
    "* 즉 GRU는 성능은 LSTM과 유사하면서 LSTM 구조는 간단화함\n",
    "\n",
    "### 1. GRU(Gated Recurrent Unit)\n",
    "* LSTM에는 출력, 입력, 삭제의 3개 게이트가 존재했으나, GRU에서는 업데이트 게이트와 리셋 게이트 두가지만 존재\n",
    "* GRU는 LSTM보다 학습속도가 빠르다고 알려져 있으나, 여러 평가에서 GRU는 LSTM과 비슷한 성능을 보인다고 알려져 있음\n",
    "\n",
    "$$r_{t}=σ(W_{xr}x_{t}+W_{hr}h_{t-1}+b_{r})$$\n",
    "$$z_{t}=σ(W_{xz}x_{t}+W_{hz}h_{t-1}+b_{z})$$\n",
    "$$g_{t}=tanh(W_{hg}(r_{t}∘h_{t-1})+W_{xg}x_{t}+b_{g})$$\n",
    "$$h_{t}=(1-z_{t})∘g_{t}+z_{t}∘h_{t-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066433a",
   "metadata": {},
   "source": [
    "GRU와 LSTM 중 어떤 것이 모델의 성능면에서 더 낫다라고 단정지어 말할 수 없으며, 기존에 LSTM을 사용하면서 최적의 하이퍼파라미터를 찾아낸 상황이라면 굳이 GRU로 바꿔서 사용할 필요는 없음\n",
    "\n",
    "* 경험적으로 데이터 양이 적을 때는 매개 변수의 양이 적은 GRU가 조금 더 낫고, 데이터 양이 더 많으면 LSTM이 더 낫다고도 함\n",
    "\n",
    "### 2. Keras의 GRU 구현\n",
    "* 사용방법은 SimpleRNN, LSTM과 동일"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e645767d",
   "metadata": {},
   "source": [
    "model.add(GRU(hidden_size, input_shape=(timesteps, input_dim)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
