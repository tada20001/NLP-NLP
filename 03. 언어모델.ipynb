{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb84a28",
   "metadata": {},
   "source": [
    "* 언어모델이란, 단어 시퀀스(문장)에 확률을 할당하는 모델\n",
    "* SLM(Statistical Language Model): 통계에 기반한 전통적인 언어모델. 그러나 통계에 기반한 언어모델은 실제 한계가 많음\n",
    "* 인공신경망이 그러한 한계를 해결해 주고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be192a",
   "metadata": {},
   "source": [
    "### 1. 통계적 언어모델 : SLM\n",
    "* 전통적 언어 모델\n",
    "* 카운트 기반의 접근 : 문자의 확률을 구하기 위해 다음 단어에 대한 예측 확률을 모두 곱함\n",
    "\n",
    "$$P\\text{(is|An adorable little boy}) = \\frac{\\text{count(An adorable little boy is})}{\\text{count(An adorable little boy })}$$\n",
    "\n",
    "    * 예를 들어 기계가 학습한 코퍼스 데이터에서 An adorable little boy가 100번 등장했는데 그 다음에 is가 등장한 경우는 30번이라고 합시다. 이 경우 는 30%임\n",
    "    \n",
    "* 한계 : 카운트 기반의 접근은 방대한 양의 데이터가 필요. 만약 훈련한 코퍼스에 해당하는 단어가 없을 경우도 발생 --> 희소문제(sparsity problem) 발생\n",
    "\n",
    "----\n",
    "* 위 문제를 완화하는 방법으로 바로 이어서 배우게 되는 n-gram 언어 모델이나 스무딩이나 백오프와 같은 여러가지 일반화(generalization) 기법이 존재\n",
    "* 하지만 희소 문제에 대한 근본적인 해결책은 되지 못함. 결국 이러한 한계로 인해 언어 모델의 트렌드는 통계적 언어 모델에서 인공 신경망 언어 모델로 넘어가게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4dcdd",
   "metadata": {},
   "source": [
    "### 2. N-gram 언어 모델(N-gram Language Model)\n",
    "\n",
    "* n-gram 언어모델은 여전히 카운트에 기반한 통계적 접근 모델. SLM의 일종\n",
    "* 다만, 이전에 등장한 모든 단어를 고려하는 것이 아니라 일부 단어만 고려\n",
    "* 이때, 일부 단어를 몇개 보느냐에 따라 n-gram의 n이 정해짐\n",
    "\n",
    "---\n",
    "* SLM의 한계는 계산하고 싶은 문장이나 단어가 훈련 데이터에 없을 경우 문제가 발생\n",
    "* 또, 계산하고자 하는 문장이 길어질 수록 해당 문장이 존재하지 않을 가능성이 높아짐(희소성 문제)\n",
    "---\n",
    "* 해결방법 : 기준 단어의 앞 단어를 전부 포함해서 카운트하는 것이 아니라, 앞 단어 중 임의의 개수만 포함해서 카운트하여 근사하자는 것임\n",
    "* 예를 들어 'An adorable little boy is spreading' 다음에 나올 단어를 예측하고 싶다고 할 때, n=4라고 한 4-gram을 이용한 언어 모델을 사용함(여기에서 An adorable little은 무시)\n",
    "\n",
    "$$P(w\\text{|boy is spreading}) = \\frac{\\text{count(boy is spreading}\\ w)}{\\text{count(boy is spreading)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290f032",
   "metadata": {},
   "source": [
    "#### 2-1. N-gram Language Model의 한계\n",
    "\n",
    "* 앞의 예에서 '작고 사랑스러운(an adorable little)'이라는 수식어를 제거하고, 반영하지 않음\n",
    "* 전체 문장을 고려한 언어모델보다 정확도가 떨어짐\n",
    "* 희소문제 : 앞에 나온 단어를 모두 보는 것보다 일부 단어만을 보는 것으로 확률을 높일 수 있으나, 희소문제 여전히 존재\n",
    "* n 설정은 trade-off 문제 : 몇단어를 볼지는 항상 trade-off가 존재. n을 크게 선택하면 실제 훈련 데이터에서 해당 n-gram 카운트할 수 있는 확률이 적어지므로 희소문제는 해결되지 않음. 그리고 모델 사이즈도 커짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30dfe5",
   "metadata": {},
   "source": [
    "### 3. 적용분야에 맞는 코퍼스(데이터) 수집 필요\n",
    "* 훈련에 사용된 도메인 코퍼스가 무엇이냐에 따라 성능이 비약적으로 달라짐\n",
    "\n",
    "\n",
    "### 4. 한국어 언어모델(Language Model for Korean Sentences)\n",
    "* 한국어는 어순이 중요하지 않다\n",
    "* 한국어는 교착어이다. 어절 단위로 토큰화할 경우 문장에서 발생가능한 단어의 수가 빨리 늘어남. 조사 등이 대표적인 사례로 토큰화를 통해 이를 분리하는 것이 중요\n",
    "* 한국어는 띄어쓰기가 제대로 지켜지지 않는다. : 제대로 되지 않은 데이터로 훈련할 경우 모델 성능 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a1e92",
   "metadata": {},
   "source": [
    "### 5. 펄플렉서티(Perplexity, PPL)\n",
    "\n",
    "* 모델 성능의 비교 문제 : 일일이 실제 작업을 해서 두 모델을 비교하면 되겠으나 시간이 많이 걸림\n",
    "* 따라서 조금은 부정확할 수 있어도 테스트 데이터에 대해 계산. 모델 내에는 자신의 성능을 수치화하여 결과를 내놓는 perplexity 방법이 있음\n",
    "\n",
    "---\n",
    "\n",
    "#### 5-1. 펄플렉서티는 언어모델을 평가하기 위한 평가지표 : PPL\n",
    "* 낮을 수록 언어모델 성능이 좋다는 의미\n",
    "* PPL은 문장의 길이로 정규화된 문장확률의 역수\n",
    "\n",
    "$$PPL(W)=\\sqrt[N]{\\frac{1}{\\prod_{i=1}^{N}P(w_{i}| w_{i-1})}}$$\n",
    "\n",
    "* PPL 평가에서 주의할 점은 테스트 데이터에 의존하므로 두개 이상의 모델을 비교할 때에는 정량적으로 양이 많고 도메인에 적합한 데이터를 사용해야 신뢰도가 높음\n",
    "* 그리고 값이 낮다고 해서 사람이 직접 느끼기에 좋은 모델이라는 보장이 없음. 직접 확인해 봐야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6559a",
   "metadata": {},
   "source": [
    "### 6. 조건부 확률\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
