{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca765ad",
   "metadata": {},
   "source": [
    "### 1. 순전파(Forward Propagation)\n",
    "\n",
    "* 입력층에서 출력층 방향으로 연산을 진행하는 과정\n",
    "* 은닉층(hidden layers)를 지나 출력층에서 예측값을 얻는 과정\n",
    "* 행렬의 곱샘으로 이해할 수 있다는 것과 다층 퍼셉트론 내의 학습가능한 매개변수 가중치 w와 편향 b를 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19c17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 행렬곱 -- 순전파 구현\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f030bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 3게 입력과 2개의 출력 구현\n",
    "model.add(Dense(2, input_dim=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244f5e8",
   "metadata": {},
   "source": [
    "* 케라스에서 .summary()를 사용하면 해당 모델에 존재하는 모든 매개변수(가중치, 편향) 갯수 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2475ffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0d52f",
   "metadata": {},
   "source": [
    "* 매개 변수(가중치와 편향)가 8개 사용됨\n",
    "\n",
    "$$h_{1} = x_{1}w_{1} + x_{2}w_{2} + x_{3}w_{3} + b_{1}$$\n",
    "$$h_{2} = x_{1}w_{4} + x_{2}w_{5} + x_{3}w_{6} + b_{2}$$\n",
    "$$[y_{1}, y_{2}] = softmax([h_{1}, h_{2}])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fea1f",
   "metadata": {},
   "source": [
    "* 다수의 샘플을 동시에 처리하는 것을 '배치연산'이라고 함\n",
    "\n",
    "##### 코드로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cb50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## layer 만들기\n",
    "model = Sequential()\n",
    "\n",
    "# 4개 입력과 8개의 출력(출력층)\n",
    "model.add(Dense(8, input_dim=4, kernel_initializer='random_uniform', activation='relu'))\n",
    "\n",
    "# 이어서 8개 출력(hidden1)\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# 이어서 3개 출력(hidden2)\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672e5d4",
   "metadata": {},
   "source": [
    "### 2. 손실함수(Loss Function)\n",
    "\n",
    "* 실제값과 예측값의 차이를 수치화해주는 함수\n",
    "* 오차가 클수록 함수의 값은 크고, 오차가 작을 수록 함수의 값은 작아짐\n",
    "* 회귀분석의 경우 평균제곱오차(MSE), 분류문제에서는 크로스엔트로피(Cross entropy) 주로 사용\n",
    "* 손실함수의 값을 최소화하는 매개변수(가중치와 편향)를 찾는 것이 딥러닝 학습과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "906075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MSE 구현\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a0935",
   "metadata": {},
   "source": [
    "* tf.keras.Loss 인스턴스를 호울하므로 다음과 같이도 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af322f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134eabf9",
   "metadata": {},
   "source": [
    "* 딥러닝 자연어 처리에서는 대부분 분류문제이므로 평균제곱오차(MSE)보다 크로스 엔트로피함수를 주로 사용\n",
    "\n",
    "#### 이진 크로스 엔트로피(Binary Cross-Entropy)\n",
    "* 출력층에서 시그모이드 함수를 사용하는 이진분류(Binary Classification)의 경우 사용\n",
    "* compile의 loss에 문자열로 'binary_crossentropy' 설정\n",
    "* 로지스틱 함수에서 사용했던 손실함수임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1154c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f648d",
   "metadata": {},
   "source": [
    "* 아래와 같이도 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90ebcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22a4af",
   "metadata": {},
   "source": [
    "#### Categorical Cross-Entropy\n",
    "* 출력층에서 소프트맥스 함수를 사용하는 다중 클래스 분류문제에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed28ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3183aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba101e",
   "metadata": {},
   "source": [
    "### 3. 배치크기(Batch Size)\n",
    "\n",
    "#### 배치크기에 따른 경사하강법(Batch Gradient Descent)\n",
    "\n",
    "* optimizer는 손실함수 값을 어떻게 줄일 것인가와 연계됨\n",
    "* 여기서 배치 개념이 이용되는데, 가중치 등 매개변수의 값을 조정하기 위해 사용하는 데이터 양을 말함\n",
    "* 전체 데이터를 갖고 조정할수도 있으나, 정해준 양의 데이터만 가지고도 매개변수 값 조정 가능\n",
    "\n",
    "---\n",
    "* BGD는 optimizer 중 하나로 오차를 구할때 전체 데이터를 고려하고, 전체 데이터에 대한 한번 훈련 횟수를 1epoch라고 함\n",
    "* BGD에서는 한번의 epoch에 모든 매개변수 업데이트를 단한번 수행함\n",
    "* BGD는 전체 데이터를 고려해서 학습하므로 한번의 매개변수 업데이트에 시간이 많이 걸리고 메모리 소모도 큼"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e576378d",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, batch_size=len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fe01e",
   "metadata": {},
   "source": [
    "#### 배치크기가 1인 확률적 경사 하강법(Stochastic Gradient Descent, SGD)\n",
    "* 위의 BGD는 전체 데이터에 대해 계산을 하기 때문에 시간이 너무 많이 소요\n",
    "* SGD는 매개변수 값 조정시 전체 데이터가 아닌 랜덤으로 선택한 하나의 데이터에 대해서만 계산\n",
    "* 따라서 더 빠르게 계산할 수 있으나,...\n",
    "\n",
    "----\n",
    "* 매개변수의 변동폭이 불규칙할 경우 정확도가 떨어질 수 있음"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c61652a2",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0263de",
   "metadata": {},
   "source": [
    "#### 미니배치 경사하강법(Mini-Batch Gradient Descent)\n",
    "\n",
    "* 배치크기를 임의로 지정하여 매개변수 조정\n",
    "* 전체 데이터 계산보다 빠르고, SGD보다 안정적임"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56627f72",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855becce",
   "metadata": {},
   "source": [
    "* 배치크기는 일반적으로 2의 n 제곱에 해당하는 숫자로 선택하는 것이 보편적\n",
    "* 기본값은 2의 5제곱 = 32\n",
    "\n",
    "### 4. Optimizer\n",
    "\n",
    "#### 모멘텀(Momentum)\n",
    "\n",
    "* 경사하강법에서 **계산된 접선의 기울기에 한시점 전의 접선의 기울기 값을 일정한 비율만큼 반영**\n",
    "* 이렇게 하면 마치 언덕에서 공이 내려올때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있음(로컬 미니멈 문제 해결)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eaa0166f",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcfee7",
   "metadata": {},
   "source": [
    "#### 아다그라드(Adagrad)\n",
    "* 각 매개변수에 동일한 학습률(learnig rate)를 적용하는 것이 비효율적임\n",
    "* Adagrad는 각 매개변수에 서로 다른 learning rate 적용이 가능"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cba4b9df",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4e872",
   "metadata": {},
   "source": [
    "#### RMSprop\n",
    "* Adagrad는 학습을 계속 진행할 경우 마지막에는 학습률이 지나치게 떨어진다는 단점이 있음\n",
    "* 이를 다른 수식으로 대체하여 단점 개선"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61796c39",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c9010",
   "metadata": {},
   "source": [
    "#### Adam\n",
    "* RMSprop와 Momentum을 합친 방법\n",
    "* 방향과 learning rate 두가지 모두 개선 가능"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7328c282",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrid=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a54ec2d",
   "metadata": {},
   "source": [
    "사용방법\n",
    "\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrid=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizers=adam, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f2e16",
   "metadata": {},
   "source": [
    "### 5. epoch와 배치 크기, iteration\n",
    "\n",
    "#### epoch\n",
    "\n",
    "* epoch : 인공신경망에서 전체 데이터에 대해 순전파와 역전파가 끝난 상태\n",
    "* 만약 epoch = 50 일 경우, 전체 데이터 단위로는 총 50번 반복 학습하게 됨\n",
    "* epoch수가 지나치거나 적으면 과적합 또는 과소적합이 발생\n",
    "\n",
    "#### batch size\n",
    "* 몇개의 데이터 단위로 매개변수를 업데이트할지 정하는 기준\n",
    "* 전체 문제 중 몇개씩 문제를 풀고나서 정답을 확인할지 문제...\n",
    "* 배치크기가 200이면 200개 샘플 단위로 가중치가 업데이트 됨\n",
    "* 주의사항은 배치크기와 배치수는 다른 개념임. 전체 데이터가 2,000일 때 배치크기를 200으로 하면 배치수는 10임\n",
    "\n",
    "#### iteration 또는 스텝\n",
    "* 한번의 epoch를 끝내기 위해 필요한 배치의 수\n",
    "* 따라서 배치크기를 작게 할 수록 커짐\n",
    "* 반대로 배치크기가 1인 확률적 하강법(SGD)에서는 모든 iteration마다 하나의 데이터를 선택하여 수행하기 때문에 모든 스텝이 iteration이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f590dc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
